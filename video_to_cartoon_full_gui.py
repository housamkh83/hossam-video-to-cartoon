# video_to_cartoon_gui.py (PyTorch Version - Requires CORRECT network.py)

import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import os
import subprocess
import cv2
import numpy as np
import threading
import queue
import time
import shutil
from PIL import Image # Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„ØµÙˆØ± Ø¨Ø´ÙƒÙ„ Ø£Ø³Ù‡Ù„ Ù…Ø¹ Torchvision
import sys # Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ ÙÙŠ ØªØ­Ø¯ÙŠØ¯ Ù…Ø³Ø§Ø± Ø§Ù„Ø³ÙƒØ±Ø¨Øª

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª PyTorch ---
# !!! Ù‡Ø§Ù…: ÙŠØ¬Ø¨ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ .pth ÙˆÙˆØ¶Ø¹Ù‡ Ø¨Ø¬Ø§Ù†Ø¨ Ø§Ù„Ø³ÙƒØ±Ø¨Øª
# --- !!! Ù‡Ø°Ø§ Ø§Ù„Ø³Ø·Ø± ÙŠØ­Ø¯Ø¯ Ø§Ù„Ù…Ø³Ø§Ø± Ù†Ø³Ø¨Ø© Ù„Ù…ÙƒØ§Ù† Ø§Ù„Ø³ÙƒØ±Ø¨Øª !!! ---
script_dir = os.path.dirname(os.path.abspath(__file__))
MODEL_PATH = os.path.join(script_dir, 'Hayao_net_G_float.pth') # <--- ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù

# !!! Ù‡Ø§Ù… Ø¬Ø¯Ø§Ù‹: ÙŠØ¬Ø¨ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„ØµØ­ÙŠØ­ (network.py) ÙˆÙˆØ¶Ø¹Ù‡ Ø¨Ø¬Ø§Ù†Ø¨ Ø§Ù„Ø³ÙƒØ±Ø¨Øª
# !!! ÙŠØ¬Ø¨ ØªØ«Ø¨ÙŠØª: PyTorch Ùˆ Torchvision (Ø§Ù†Ø¸Ø± https://pytorch.org/)
try:
    import torch
    import torchvision.transforms as transforms
    # --- !!! Ù‡Ø°Ø§ Ø§Ù„Ø³Ø·Ø± Ø§Ù„Ø­Ø§Ø³Ù… ÙŠØªØ·Ù„Ø¨ ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù network.py Ø§Ù„ØµØ­ÙŠØ­ Ø¨Ù†ÙØ³ Ø§Ù„Ù…Ø¬Ù„Ø¯ !!! ---
    from network import Generator  # <--- Ø§Ø³ØªÙŠØ±Ø§Ø¯ ØªØ¹Ø±ÙŠÙ Ø¨Ù†ÙŠØ© Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„ØµØ­ÙŠØ­
    PYTORCH_AVAILABLE = True
    MODEL_DEF_AVAILABLE = True
except ImportError as e:
    PYTORCH_AVAILABLE = False
    # ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø®Ø·Ø£ Ø¨Ø³Ø¨Ø¨ Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ network.py Ø£Ùˆ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ torch/torchvision
    if 'network' in str(e) or 'Generator' in str(e):
         MODEL_DEF_AVAILABLE = False
         print("Ø®Ø·Ø£ Ø­Ø§Ø³Ù…: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (network.py) Ø£Ùˆ Ø§Ù„ÙƒÙ„Ø§Ø³ Generator Ø¨Ø¯Ø§Ø®Ù„Ù‡. ÙŠØ±Ø¬Ù‰ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµØ­ÙŠØ­ ÙˆÙˆØ¶Ø¹Ù‡ Ø¨Ø¬Ø§Ù†Ø¨ Ø§Ù„Ø³ÙƒØ±Ø¨Øª.")
    else:
        MODEL_DEF_AVAILABLE = True # Ù†ÙØªØ±Ø¶ Ø£Ù† ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ù…ØªØ§Ø­Ù‹Ø§ Ù„ÙƒÙ† Ø§Ù„Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø¨Ø§ÙŠØªÙˆØ±Ø´
        print(f"ØªØ­Ø°ÙŠØ±: Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªÙŠØ±Ø§Ø¯ PyTorch Ø£Ùˆ Ù…ÙƒÙˆÙ†Ø§ØªÙ‡: {e}. ØªØ£ÙƒØ¯ Ù…Ù† ØªØ«Ø¨ÙŠØª torch Ùˆ torchvision.")
        print("Ù„Ù† ÙŠØ¹Ù…Ù„ ØªØ­ÙˆÙŠÙ„ CartoonGAN.")
except Exception as e: # Catch other potential errors during import
    PYTORCH_AVAILABLE = False
    MODEL_DEF_AVAILABLE = False
    print(f"Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª: {e}")


# --- Ù…ØªØºÙŠØ±Ø§Øª Ø¹Ø§Ù…Ø© ---
video_path = ""
conversion_thread = None
stop_event = threading.Event()

# --- ÙˆØ¸Ø§Ø¦Ù Ù…Ø³Ø§Ø¹Ø¯Ø© ---
# def resource_path(relative_path): # Ù‚Ø¯ Ù„Ø§ Ù†Ø­ØªØ§Ø¬Ù‡Ø§ Ø¥Ø°Ø§ Ø§Ø³ØªØ®Ø¯Ù…Ù†Ø§ __file__
#     try:
#         base_path = sys._MEIPASS
#     except Exception:
#         base_path = os.path.abspath(".")
#     return os.path.join(base_path, relative_path)

def create_output_dirs(base_folder="output"):
    """ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯ Ø±Ø¦ÙŠØ³ÙŠ Ø¨Ø¬Ø§Ù†Ø¨ Ø§Ù„Ø³ÙƒØ±Ø¨Øª """
    script_dir = os.path.dirname(os.path.abspath(__file__)) # Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø­Ø§Ù„ÙŠ Ù„Ù„Ø³ÙƒØ±Ø¨Øª
    main_output_dir = os.path.join(script_dir, base_folder) # Ù…Ø¬Ù„Ø¯ output Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    output_dir = os.path.join(main_output_dir, f"conversion_{timestamp}") # Ù…Ø¬Ù„Ø¯ Ù„Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©
    frames_dir = os.path.join(output_dir, "frames")
    cartoon_frames_dir = os.path.join(output_dir, "cartoon_frames")
    os.makedirs(output_dir, exist_ok=True) # Ø³ÙŠÙ‚ÙˆÙ… Ø¨Ø§Ù†Ø´Ø§Ø¡ main_output_dir Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
    os.makedirs(frames_dir, exist_ok=True)
    os.makedirs(cartoon_frames_dir, exist_ok=True)
    return output_dir, frames_dir, cartoon_frames_dir

def select_video():
    global video_path
    path = filedialog.askopenfilename(
        title="Ø§Ø®ØªØ± Ù…Ù„Ù ÙÙŠØ¯ÙŠÙˆ",
        filetypes=[("Video files", "*.mp4;*.avi;*.mov;*.mkv"), ("All files", "*.*")]
    )
    if path:
        video_path = path
        label_status.config(text=f"ØªÙ… Ø§Ø®ØªÙŠØ§Ø±: {os.path.basename(video_path)}")
        # ØªÙØ¹ÙŠÙ„ Ø²Ø± Ø§Ù„ØªØ­ÙˆÙŠÙ„ ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª ÙˆØ§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¬Ø§Ù‡Ø²Ø©
        if PYTORCH_AVAILABLE and MODEL_DEF_AVAILABLE and os.path.exists(MODEL_PATH):
             btn_convert.config(state=tk.NORMAL)
        else:
             btn_convert.config(state=tk.DISABLED)
             check_pytorch_and_model(show_error=False) # Ø¹Ø±Ø¶ ØªØ­Ø°ÙŠØ± ÙÙŠ Ø§Ù„Ø­Ø§Ù„Ø©
    else:
        label_status.config(text="Ù„Ù… ÙŠØªÙ… Ø§Ø®ØªÙŠØ§Ø± ÙÙŠØ¯ÙŠÙˆ.")
        btn_convert.config(state=tk.DISABLED)

def check_ffmpeg():
    if shutil.which("ffmpeg") is None:
        messagebox.showerror("Ø®Ø·Ø£ FFMpeg", "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨Ø±Ù†Ø§Ù…Ø¬ ffmpeg.\nÙŠØ±Ø¬Ù‰ ØªØ«Ø¨ÙŠØªÙ‡ ÙˆØ¥Ø¶Ø§ÙØªÙ‡ Ø¥Ù„Ù‰ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© (PATH) Ø£Ùˆ ÙˆØ¶Ø¹Ù‡ Ø¨Ø¬Ø§Ù†Ø¨ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬.")
        return False
    return True

def check_pytorch_and_model(show_error=True):
    # ÙŠØªÙ… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† PYTORCH_AVAILABLE Ùˆ MODEL_DEF_AVAILABLE Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠ
    if not PYTORCH_AVAILABLE:
        # Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© ØªÙ… Ø·Ø¨Ø§Ø¹ØªÙ‡Ø§ Ø¨Ø§Ù„ÙØ¹Ù„ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠ
        if show_error: messagebox.showerror("Ø®Ø·Ø£ PyTorch", "Ù…ÙƒØªØ¨Ø© PyTorch Ø£Ùˆ Torchvision ØºÙŠØ± Ù…Ø«Ø¨ØªØ© Ø£Ùˆ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø¹Ù†Ø¯ Ø§Ø³ØªÙŠØ±Ø§Ø¯Ù‡Ø§.\nØ±Ø§Ø¬Ø¹ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ ÙÙŠ Ø§Ù„Ø·Ø±ÙÙŠØ© (console).")
        else: label_status.config(text="ØªØ­Ø°ÙŠØ±: PyTorch/Torchvision ØºÙŠØ± Ù…ØªØ§Ø­Ø©.")
        return False
    if not MODEL_DEF_AVAILABLE:
         # Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© ØªÙ… Ø·Ø¨Ø§Ø¹ØªÙ‡Ø§ Ø¨Ø§Ù„ÙØ¹Ù„ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠ
         if show_error: messagebox.showerror("Ø®Ø·Ø£ ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„", "Ù…Ù„Ù ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (network.py) ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ø£Ùˆ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„ÙƒÙ„Ø§Ø³ Generator Ù…Ù†Ù‡.\nØ±Ø§Ø¬Ø¹ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ ÙÙŠ Ø§Ù„Ø·Ø±ÙÙŠØ© (console).")
         else: label_status.config(text="ØªØ­Ø°ÙŠØ±: Ù…Ù„Ù ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (network.py) Ù…ÙÙ‚ÙˆØ¯ Ø£Ùˆ ØºÙŠØ± ØµØ­ÙŠØ­.")
         return False
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù Ø§Ù„Ø£ÙˆØ²Ø§Ù† .pth
    if not os.path.exists(MODEL_PATH):
        if show_error: messagebox.showerror("Ø®Ø·Ø£ Ù…Ù„Ù Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„", f"Ù…Ù„Ù Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (.pth) ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯!\nØ§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹: {MODEL_PATH}\n\nÙ‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù .pth ÙˆØ¶Ø¹Ù‡ ÙÙŠ Ù†ÙØ³ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø³ÙƒØ±Ø¨Øª.")
        else: label_status.config(text=f"ØªØ­Ø°ÙŠØ±: Ù…Ù„Ù Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ({os.path.basename(MODEL_PATH)}) Ù…ÙÙ‚ÙˆØ¯.")
        return False
    return True

# --- ÙˆØ¸ÙŠÙØ© Ø§Ù„ØªØ­ÙˆÙŠÙ„ (ØªØ¹Ù…Ù„ ÙÙŠ Thread Ù…Ù†ÙØµÙ„) ---
def run_conversion(q, vid_path):
    global stop_event
    stop_event.clear()

    # 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ù…Ø¨Ø¯Ø¦ÙŠ (ØªÙ… Ù†Ù‚Ù„Ù‡ Ø¥Ù„Ù‰ start_conversion Ù„ÙŠØ¹Ø±Ø¶ Ø§Ù„Ø®Ø·Ø£ Ù…Ø¨Ø§Ø´Ø±Ø©)
    q.put(("status", "Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ø¶ÙŠØ±..."))
    q.put(("progress", 0))

    # 2. Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬
    try:
        output_dir, frames_dir, cartoon_frames_dir = create_output_dirs()
    except Exception as e:
        q.put(("status", f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª: {e}"))
        q.put(("finished", False))
        return

    # 3. Ø­Ø³Ø§Ø¨ FPS ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª
    try:
        q.put(("status", "Ø¬Ø§Ø±ÙŠ Ø­Ø³Ø§Ø¨ FPS..."))
        cap = cv2.VideoCapture(vid_path)
        if not cap.isOpened(): raise Exception("Ù„Ø§ ÙŠÙ…ÙƒÙ† ÙØªØ­ Ù…Ù„Ù Ø§Ù„ÙÙŠØ¯ÙŠÙˆ.")
        fps = cap.get(cv2.CAP_PROP_FPS)
        frame_count_approx = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        cap.release()
        if fps <= 0: fps = 25
        q.put(("status", f"FPS: {fps:.2f} - Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯: {width}x{height}"))

        q.put(("status", "Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª..."))
        frame_filename_pattern = os.path.join(frames_dir, "frame_%06d.png")
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† ffmpeg Ù…ØªØ§Ø­ Ù‚Ø¨Ù„ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡
        if not check_ffmpeg():
            raise Exception("FFmpeg ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ø£Ùˆ ØºÙŠØ± Ù…ØªØ§Ø­ ÙÙŠ Ø§Ù„Ù€ PATH.")

        ffmpeg_command = [
            'ffmpeg', '-i', vid_path, '-vf', f'fps={fps}',
            '-vsync', 'vfr', frame_filename_pattern
        ]
        # Ø¥Ø®ÙØ§Ø¡ Ù†Ø§ÙØ°Ø© ffmpeg Ø¹Ù„Ù‰ ÙˆÙŠÙ†Ø¯ÙˆØ²
        startupinfo = None
        if os.name == 'nt':
            startupinfo = subprocess.STARTUPINFO()
            startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
            startupinfo.wShowWindow = subprocess.SW_HIDE

        process = subprocess.Popen(ffmpeg_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True, startupinfo=startupinfo)
        stdout, stderr = process.communicate()
        if process.returncode != 0:
             print("FFmpeg stderr:", stderr)
             # Ù…Ø­Ø§ÙˆÙ„Ø© ØªÙ‚Ø¯ÙŠÙ… Ø±Ø³Ø§Ù„Ø© Ø®Ø·Ø£ Ø£ÙˆØ¶Ø­ Ù‚Ù„ÙŠÙ„Ø§Ù‹
             error_message = f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª Ø¨ÙˆØ§Ø³Ø·Ø© ffmpeg.\nØ§Ù„Ø±Ù…Ø²: {process.returncode}"
             if "No such file or directory" in stderr:
                 error_message += "\nØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ù…Ø³Ø§Ø± Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ØµØ­ÙŠØ­ ÙˆÙ„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø­Ø±ÙˆÙ Ø®Ø§ØµØ© Ø¬Ø¯Ø§Ù‹."
             elif "Permission denied" in stderr:
                 error_message += "\nØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ø°ÙˆÙ†Ø§Øª Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© Ù„Ù„Ù…Ù„Ù ÙˆØ§Ù„ÙƒØªØ§Ø¨Ø© Ù„Ù„Ù…Ø¬Ù„Ø¯."
             else:
                  error_message += f"\n{stderr[:500]}..." # Ø¹Ø±Ø¶ Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ø®Ø·Ø£
             raise Exception(error_message)


        extracted_frames = sorted(os.listdir(frames_dir))
        num_frames = len(extracted_frames)
        if num_frames == 0: raise Exception("ÙØ´Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª Ø£Ùˆ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¥Ø·Ø§Ø±Ø§Øª ÙÙŠ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ.")
        q.put(("status", f"ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {num_frames} Ø¥Ø·Ø§Ø±."))

    except Exception as e:
        q.put(("status", f"Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª: {e}"))
        q.put(("finished", False))
        return

    # 4. ØªØ­Ù…ÙŠÙ„ Ù…ÙˆØ¯ÙŠÙ„ PyTorch
    model = None
    try:
        q.put(("status", "Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ù…ÙˆØ¯ÙŠÙ„ PyTorch..."))
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        q.put(("status", f"Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¬Ù‡Ø§Ø²: {device}"))

        # --- !!! Ù‡Ù†Ø§ ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙƒÙ„Ø§Ø³ Generator Ø§Ù„Ù…Ø³ØªÙˆØ±Ø¯ Ù…Ù† network.py Ø§Ù„ØµØ­ÙŠØ­ !!! ---
        model = Generator()
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£ÙˆØ²Ø§Ù†
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… strict=False Ù‚Ø¯ ÙŠØªØ¬Ø§ÙˆØ² Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©/Ø§Ù„Ø²Ø§Ø¦Ø¯Ø© Ù„ÙƒÙ†Ù‡ Ù„ÙŠØ³ Ø­Ù„Ø§Ù‹ Ù„Ù„Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©!
        # Ø§Ù„Ø£ÙØ¶Ù„ Ù‡Ùˆ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØªØ·Ø§Ø¨Ù‚ network.py Ù…Ø¹ Ù…Ù„Ù .pth
        try:
             # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµØ§Ø±Ù…Ø© Ø£ÙˆÙ„Ø§Ù‹ (strict=True Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹)
             model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
        except RuntimeError as load_error:
             # Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµØ§Ø±Ù… Ø¨Ø³Ø¨Ø¨ Ø¹Ø¯Ù… ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ù…ÙØ§ØªÙŠØ­
             if 'Missing key(s)' in str(load_error) or 'Unexpected key(s)' in str(load_error):
                  error_msg = f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„:\nØ¹Ø¯Ù… ØªØ·Ø§Ø¨Ù‚ Ø¨ÙŠÙ† Ø¨Ù†ÙŠØ© Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙÙŠ 'network.py' ÙˆØ§Ù„Ø£ÙˆØ²Ø§Ù† ÙÙŠ '{os.path.basename(MODEL_PATH)}'.\n"
                  error_msg += "ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ù„Ù 'network.py' Ø§Ù„ØµØ­ÙŠØ­ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„.\n\n"
                  error_msg += f"ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø·Ø£:\n{load_error}"
                  q.put(("status", error_msg)) # Ø¹Ø±Ø¶ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£ Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…
                  q.put(("finished", False))
                  return # Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªÙ†ÙÙŠØ° Ù„Ø£Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„Ù‡ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­
             else:
                  raise load_error # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø®Ø·Ø£ Ù…Ù† Ù†ÙˆØ¹ Ø¢Ø®Ø±ØŒ Ø£Ø¹Ø¯ Ø±ÙØ¹Ù‡

        model.to(device)
        model.eval() # Ø¶Ø±ÙˆØ±ÙŠ Ø¬Ø¯Ø§Ù‹
        q.put(("status", "ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù…ÙˆØ¯ÙŠÙ„ PyTorch Ø¨Ù†Ø¬Ø§Ø­."))

        # ØªØ¹Ø±ÙŠÙ Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ­ÙˆÙŠÙ„ (Preprocessing) - ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†Ù‡Ø§ Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„
        img_transforms = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
        ])

    except Exception as e:
        q.put(("status", f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø£Ùˆ Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ÙˆØ¯ÙŠÙ„ PyTorch: {e}"))
        q.put(("finished", False))
        return

    # 5. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª (PyTorch Inference)
    q.put(("status", "Ø¬Ø§Ø±ÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª Ø¥Ù„Ù‰ ÙƒØ±ØªÙˆÙ† (Ù‚Ø¯ ØªÙƒÙˆÙ† Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¨Ø·ÙŠØ¦Ø©)..."))
    start_time = time.time()
    processed_count = 0
    try:
        with torch.no_grad(): # Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹
            for i, frame_name in enumerate(extracted_frames):
                if stop_event.is_set():
                    q.put(("status", "ØªÙ… Ø§Ù„Ø¥ÙŠÙ‚Ø§Ù Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…."))
                    q.put(("finished", False))
                    return

                img_path = os.path.join(frames_dir, frame_name)
                try:
                    img_pil = Image.open(img_path).convert('RGB')
                except Exception as img_err:
                     print(f"ØªØ­Ø°ÙŠØ±: ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¥Ø·Ø§Ø± {frame_name} Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… PIL: {img_err}, Ø³ÙŠØªÙ… ØªØ®Ø·ÙŠÙ‡.")
                     continue # Ø§Ù†ØªÙ‚Ù„ Ù„Ù„Ø¥Ø·Ø§Ø± Ø§Ù„ØªØ§Ù„ÙŠ

                # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª
                input_tensor = img_transforms(img_pil).unsqueeze(0).to(device)

                # Inference
                output_tensor = model(input_tensor)

                # Postprocessing
                output_image_np = output_tensor.squeeze(0).cpu().numpy()
                output_image_np = output_image_np * 0.5 + 0.5
                output_image_np = np.transpose(output_image_np, (1, 2, 0))
                output_image_np = (output_image_np * 255.0)
                output_image_np = np.clip(output_image_np, 0, 255).astype(np.uint8)
                cartoon_img_bgr = cv2.cvtColor(output_image_np, cv2.COLOR_RGB2BGR)

                # Ø­ÙØ¸ Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„ÙƒØ±ØªÙˆÙ†ÙŠ
                cartoon_frame_path = os.path.join(cartoon_frames_dir, frame_name)
                cv2.imwrite(cartoon_frame_path, cartoon_img_bgr)
                processed_count += 1

                # ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ‚Ø¯Ù…
                progress_percent = (i + 1) * 100 / num_frames
                elapsed_time = time.time() - start_time
                est_total_time = (elapsed_time / (i + 1)) * num_frames if (i + 1) > 0 else 0
                est_remaining = est_total_time - elapsed_time
                q.put(("progress", progress_percent))
                q.put(("status", f"Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¥Ø·Ø§Ø± {i+1}/{num_frames} - Ù…ØªØ¨Ù‚ÙŠ: {time.strftime('%H:%M:%S', time.gmtime(est_remaining))}"))

    except Exception as e:
        q.put(("status", f"Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª Ø¨Ù€ PyTorch: {e}"))
        q.put(("finished", False))
        return
    finally:
        # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ø±ÙŠØ± Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        if model is not None: del model
        if 'input_tensor' in locals(): del input_tensor
        if 'output_tensor' in locals(): del output_tensor
        if torch.cuda.is_available(): torch.cuda.empty_cache()


    # 6. Ø¥Ø¹Ø§Ø¯Ø© ØªØ¬Ù…ÙŠØ¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
    q.put(("status", "Ø¬Ø§Ø±ÙŠ Ø¥Ø¹Ø§Ø¯Ø© ØªØ¬Ù…ÙŠØ¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ..."))
    q.put(("progress", 100))
    try:
        video_basename = os.path.splitext(os.path.basename(vid_path))[0]
        output_video_path = os.path.join(output_dir, f"{video_basename}_cartoon_pytorch.mp4")

        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø¨Ø¹Ø§Ø¯ Ø£ÙˆÙ„ Ø¥Ø·Ø§Ø± ÙƒØ±ØªÙˆÙ†ÙŠ
        first_cartoon_frame_path = os.path.join(cartoon_frames_dir, extracted_frames[0])
        first_frame = cv2.imread(first_cartoon_frame_path)
        if first_frame is None: raise Exception("Ù„Ø§ ÙŠÙ…ÙƒÙ† Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„ÙƒØ±ØªÙˆÙ†ÙŠ Ø§Ù„Ø£ÙˆÙ„.")
        out_height, out_width, _ = first_frame.shape

        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ ffmpeg Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ù‚Ø¨Ù„ Ø§Ù„ØªØ¬Ù…ÙŠØ¹
        if not check_ffmpeg():
            raise Exception("FFmpeg ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ø£Ùˆ ØºÙŠØ± Ù…ØªØ§Ø­ ÙÙŠ Ø§Ù„Ù€ PATH.")

        reassemble_command = [
            'ffmpeg', '-framerate', str(fps),
            '-i', os.path.join(cartoon_frames_dir, "frame_%06d.png"),
            '-i', vid_path, '-map', '0:v:0', '-map', '1:a:0?',
            '-c:v', 'libx264', '-preset', 'medium', '-crf', '23', '-pix_fmt', 'yuv420p',
            '-c:a', 'aac', '-b:a', '128k', '-shortest', '-y', output_video_path
        ]

        q.put(("status", "ØªØ´ØºÙŠÙ„ FFMpeg Ù„ØªØ¬Ù…ÙŠØ¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ..."))
        # Ø¥Ø®ÙØ§Ø¡ Ù†Ø§ÙØ°Ø© ffmpeg
        startupinfo = None
        if os.name == 'nt':
            startupinfo = subprocess.STARTUPINFO()
            startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
            startupinfo.wShowWindow = subprocess.SW_HIDE

        process = subprocess.Popen(reassemble_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True, startupinfo=startupinfo)
        stdout, stderr = process.communicate()
        if process.returncode != 0:
            print("FFmpeg Reassemble stderr:", stderr)
            if os.path.exists(output_video_path) and os.path.getsize(output_video_path) > 0 :
                 q.put(("status", f"ØªØ­Ø°ÙŠØ±: Ø®Ø·Ø£ Ø¨Ù†Ø³Ø® Ø§Ù„ØµÙˆØªØŸ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù‡Ù†Ø§: {output_video_path}"))
                 q.put(("finished", True, output_dir))
            else:
                 raise Exception(f"ÙØ´Ù„ FFMpeg ÙÙŠ ØªØ¬Ù…ÙŠØ¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ.\n{stderr[:500]}...")
        else:
             q.put(("status", f"âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„! Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ÙˆØ§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ù‡Ù†Ø§: {output_dir}"))
             q.put(("finished", True, output_dir))

    except Exception as e:
        q.put(("status", f"Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¥Ø¹Ø§Ø¯Ø© ØªØ¬Ù…ÙŠØ¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ: {e}"))
        q.put(("finished", False))
        return

    # 7. (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) Ø­Ø°Ù Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©
    # try:
    #     q.put(("status", "Ø¬Ø§Ø±ÙŠ Ø­Ø°Ù Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©..."))
    #     shutil.rmtree(frames_dir)
    #     # shutil.rmtree(cartoon_frames_dir) # Ù‚Ø¯ ØªØ±ØºØ¨ ÙÙŠ Ø¥Ø¨Ù‚Ø§Ø¡ Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª Ø§Ù„ÙƒØ±ØªÙˆÙ†ÙŠØ©
    # except Exception as e:
    #     q.put(("status", f"ØªØ­Ø°ÙŠØ±: Ù„Ù… ÙŠØªÙ… Ø­Ø°Ù Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©: {e}"))

def start_conversion():
    global conversion_thread, stop_event

    # --- Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ø£ÙˆÙ„ÙŠ Ù‚Ø¨Ù„ Ø§Ù„Ø¨Ø¯Ø¡ ---
    if not check_ffmpeg(): return
    if not check_pytorch_and_model(show_error=True): return # ÙŠØªØ­Ù‚Ù‚ Ù…Ù† ÙƒÙ„ Ø´ÙŠØ¡ (torch, network.py, model.pth)

    if conversion_thread and conversion_thread.is_alive():
        messagebox.showwarning("Ù‚ÙŠØ¯ Ø§Ù„ØªØ´ØºÙŠÙ„", "Ø¹Ù…Ù„ÙŠØ© ØªØ­ÙˆÙŠÙ„ Ø£Ø®Ø±Ù‰ Ù‚ÙŠØ¯ Ø§Ù„ØªØ´ØºÙŠÙ„ Ø¨Ø§Ù„ÙØ¹Ù„.")
        return

    if not video_path:
        messagebox.showerror("Ø®Ø·Ø£", "ÙŠØ±Ø¬Ù‰ Ø§Ø®ØªÙŠØ§Ø± Ù…Ù„Ù ÙÙŠØ¯ÙŠÙˆ Ø£ÙˆÙ„Ø§Ù‹.")
        return

    # ØªØ¹Ø·ÙŠÙ„ ÙˆØªÙØ¹ÙŠÙ„ Ø§Ù„Ø£Ø²Ø±Ø§Ø±
    btn_select.config(state=tk.DISABLED)
    btn_convert.config(state=tk.DISABLED)
    btn_stop.config(state=tk.NORMAL)
    progress_bar['value'] = 0
    label_status.config(text="Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ­ÙˆÙŠÙ„ (PyTorch)...")

    # Ø¨Ø¯Ø¡ Ø§Ù„Ù€ Thread
    conversion_thread = threading.Thread(target=run_conversion, args=(update_queue, video_path), daemon=True)
    conversion_thread.start()
    root.after(100, check_queue) # Ø¨Ø¯Ø¡ Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù€ Queue

def stop_conversion():
    global stop_event
    if conversion_thread and conversion_thread.is_alive():
        print("Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø¥ÙŠÙ‚Ø§Ù...")
        stop_event.set()
        btn_stop.config(state=tk.DISABLED)
        label_status.config(text="Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¥ÙŠÙ‚Ø§Ù...")
    else:
        print("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¹Ù…Ù„ÙŠØ© Ù„Ø¥ÙŠÙ‚Ø§ÙÙ‡Ø§.")

def check_queue():
    """ ØªÙØ­Øµ Ø§Ù„Ù€ Queue Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ù…Ù† Ø§Ù„Ù€ Thread Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ """
    try:
        while True:
            message = update_queue.get_nowait() # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø¨Ø¯ÙˆÙ† Ø§Ù†ØªØ¸Ø§Ø±
            msg_type = message[0]
            msg_data = message[1]

            if msg_type == "status":
                label_status.config(text=msg_data)
                # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø±Ø³Ø§Ù„Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ØªÙØ§ØµÙŠÙ„ Ø®Ø·Ø£ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ØŒ Ø§Ø¹Ø±Ø¶Ù‡Ø§ ÙÙŠ messagebox
                if "Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„" in msg_data and len(msg_data) > 100: # ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù†Ù‡Ø§ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ø·ÙˆÙŠÙ„Ø©
                    messagebox.showerror("Ø®Ø·Ø£ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„", msg_data)

            elif msg_type == "progress":
                progress_bar['value'] = msg_data
            elif msg_type == "finished":
                success = msg_data
                output_location = message[2] if len(message) > 2 else None
                if success:
                    messagebox.showinfo("Ø§ÙƒØªÙ…Ù„", f"ØªÙ…Øª Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­!\nØ§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯:\n{output_location}")
                # else: # Ø¹Ø±Ø¶ Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ø£Ø®ÙŠØ± Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù‚Ø¯ ØªÙ… Ø¹Ø±Ø¶Ù‡ Ø¨Ø§Ù„ÙØ¹Ù„
                #    final_status = label_status.cget("text")
                #    if "Ø®Ø·Ø£" in final_status and "ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„" not in final_status:
                #       messagebox.showerror("Ø®Ø·Ø£", final_status)


                # Ø¥Ø¹Ø§Ø¯Ø© Ø¶Ø¨Ø· Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
                btn_select.config(state=tk.NORMAL)
                # Ø£Ø¹Ø¯ ØªÙØ¹ÙŠÙ„ Ø²Ø± Ø§Ù„ØªØ­ÙˆÙŠÙ„ ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù„Ø§ ÙŠØ²Ø§Ù„ Ù…Ø­Ø¯Ø¯Ø§Ù‹ ÙˆØ§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø¬Ø§Ù‡Ø²Ø©
                if video_path and PYTORCH_AVAILABLE and MODEL_DEF_AVAILABLE and os.path.exists(MODEL_PATH):
                    btn_convert.config(state=tk.NORMAL)
                else:
                     btn_convert.config(state=tk.DISABLED)
                btn_stop.config(state=tk.DISABLED)
                progress_bar['value'] = 0
                # stop_event.clear() # Ù„Ø§ ØªÙ…Ø³Ø­Ù‡Ø§ Ù‡Ù†Ø§ØŒ Ø§Ù…Ø³Ø­Ù‡Ø§ ÙÙŠ Ø¨Ø¯Ø§ÙŠØ© run_conversion
                return # Ø£ÙˆÙ‚Ù Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù€ Queue Ù„Ù‡Ø°Ù‡ Ø§Ù„Ø¯ÙˆØ±Ø©

    except queue.Empty:
        # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù€ Queue ÙØ§Ø±ØºØ©ØŒ Ø§Ø³ØªÙ…Ø± ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù„Ø§Ø­Ù‚Ø§Ù‹ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù€ Thread Ù„Ø§ ÙŠØ²Ø§Ù„ ÙŠØ¹Ù…Ù„
        if conversion_thread and conversion_thread.is_alive():
            root.after(100, check_queue)
        else: # Thread Ø§Ù†ØªÙ‡Ù‰ ÙˆÙ„Ù… ØªÙƒÙ† Ù‡Ù†Ø§Ùƒ Ø±Ø³Ø§Ù„Ø© "finished" (ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ù„ÙƒÙ† Ø§Ø­ØªÙŠØ§Ø·ÙŠ)
              btn_select.config(state=tk.NORMAL)
              if video_path and PYTORCH_AVAILABLE and MODEL_DEF_AVAILABLE and os.path.exists(MODEL_PATH): btn_convert.config(state=tk.NORMAL)
              else: btn_convert.config(state=tk.DISABLED)
              btn_stop.config(state=tk.DISABLED)


# --- ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Tkinter) ---
root = tk.Tk()
root.title("CartoonifyVideo - ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¥Ù„Ù‰ ÙƒØ±ØªÙˆÙ† (PyTorch)")
root.geometry("500x250")

# Ø§Ø³ØªØ®Ø¯Ø§Ù… Style Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø¸Ù‡Ø± Ù‚Ù„ÙŠÙ„Ø§Ù‹ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
style = ttk.Style()
# ÙŠÙ…ÙƒÙ†Ùƒ ØªØ¬Ø±Ø¨Ø© Ø«ÙŠÙ…Ø§Øª Ù…Ø®ØªÙ„ÙØ© Ù…Ø«Ù„ 'clam', 'alt', 'default', 'vista' Ø¹Ù„Ù‰ ÙˆÙŠÙ†Ø¯ÙˆØ²
# style.theme_use('vista')

# Ø¥Ø·Ø§Ø± Ù„Ù„Ù…Ø­ØªÙˆÙ‰
frame = ttk.Frame(root, padding="10")
frame.pack(expand=True, fill=tk.BOTH)

# Ø§Ù„Ø£Ø²Ø±Ø§Ø± ÙˆØ§Ù„Ø¹Ù†Ø§ØµØ±
btn_select = ttk.Button(frame, text="ğŸ“‚ Ø§Ø®ØªÙŠØ§Ø± ÙÙŠØ¯ÙŠÙˆ", command=select_video)
btn_select.pack(pady=10, fill=tk.X)

# Ø²Ø± Ø§Ù„ØªØ­ÙˆÙŠÙ„ ÙŠØ¨Ø¯Ø£ Ù…Ø¹Ø·Ù„Ø§Ù‹
btn_convert = ttk.Button(frame, text="ğŸš€ ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ÙƒØ±ØªÙˆÙ† (PyTorch)", command=start_conversion, state=tk.DISABLED)
btn_convert.pack(pady=5, fill=tk.X)

btn_stop = ttk.Button(frame, text="ğŸ›‘ Ø¥ÙŠÙ‚Ø§Ù", command=stop_conversion, state=tk.DISABLED)
btn_stop.pack(pady=5, fill=tk.X)

progress_bar = ttk.Progressbar(frame, orient="horizontal", length=300, mode="determinate")
progress_bar.pack(pady=10, fill=tk.X)

label_status = ttk.Label(frame, text="ÙŠØ±Ø¬Ù‰ Ø§Ø®ØªÙŠØ§Ø± Ù…Ù„Ù ÙÙŠØ¯ÙŠÙˆ Ù„Ù„Ø¨Ø¯Ø¡.", anchor=tk.CENTER, wraplength=480)
label_status.pack(pady=10, fill=tk.X)

# --- Ø¨Ø¯Ø¡ Ø§Ù„ØªØ´ØºÙŠÙ„ ---
update_queue = queue.Queue() # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù€ Queue Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ù€ Threads

# Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ø£ÙˆÙ„ÙŠ Ø¹Ù†Ø¯ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ´ØºÙŠÙ„ ÙˆØ¹Ø±Ø¶ Ø§Ù„Ø­Ø§Ù„Ø©
check_pytorch_and_model(show_error=False) # Ù„Ø§ ØªØ¹Ø±Ø¶ messageboxØŒ ÙÙ‚Ø· ØªØ­Ø¯Ø« label_status

root.mainloop()